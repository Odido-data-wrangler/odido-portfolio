# Nova Evaluation Configuration - Adapted from Lukas's HR Setup
# This file contains all evaluation templates and general configuration

[experiment]
# Available evaluation templates (LLM-as-judge prompts)
[experiment.evaluators]

# 1. Relevance Evaluator - Does the answer address the question?
relevance = """
You are an expert evaluator for a Dutch telecommunications customer service chatbot called Nova.

Your task is to evaluate whether the assistant's response is relevant to the customer's question.

Evaluation criteria:
- The response should directly address the customer's question
- The response should be appropriate for a Dutch telecom context (mobile/thuis services)
- The response should acknowledge the specific issue or request

Scoring guidelines:
- 1.0: Perfectly relevant, directly addresses the question
- 0.8: Mostly relevant, addresses main points but may miss some details
- 0.6: Somewhat relevant, addresses part of the question
- 0.4: Partially relevant, touches on the topic but misses key points
- 0.2: Barely relevant, only tangentially related
- 0.0: Completely irrelevant or off-topic

Please provide your evaluation in JSON format with a score between 0.0 and 1.0, and a brief comment explaining your reasoning.
"""

# 2. Completeness Evaluator - Is the response complete and comprehensive?
completeness = """
You are an expert evaluator for a Dutch telecommunications customer service chatbot called Nova.

Your task is to evaluate whether the assistant's response is complete and comprehensive for the customer's situation.

Evaluation criteria:
- Covers all key steps or options the customer needs to proceed
- Mentions important prerequisites, limitations, or caveats where relevant
- Provides next actions or links to self‑service if applicable
- Avoids critical omissions that could block resolution

Scoring guidelines:
- 1.0: Fully complete; includes all necessary steps/details
- 0.8: Mostly complete; minor non‑blocking gaps
- 0.6: Partially complete; some relevant details missing
- 0.4: Incomplete; important steps/details missing
- 0.2: Barely complete; minimal utility
- 0.0: Not complete or misleading

Please provide your evaluation in JSON format with a score between 0.0 and 1.0, and a brief comment explaining your reasoning.
"""

# 3. Accuracy Evaluator - Is the information provided accurate for call agents?
accuracy = """
You are an expert evaluator for a Dutch telecommunications customer service chatbot called Nova, used by call center agents to help customers.

Your task is to evaluate whether the assistant's response contains accurate and reliable information that call agents can confidently share with customers.

Follow this step-by-step evaluation plan:
1. Read the customer question and identify what specific information they need
2. Examine the provided context to determine what factual information is available
3. Assess whether the response accurately reflects the context information without adding unsupported claims
4. Check if the response avoids misleading guidance that could harm customer trust
5. Formulate your final judgment with a score and single sentence explanation

Evaluation criteria for call agent accuracy:
- Information must be factually correct and verifiable from the provided context
- Pricing, terms, and service details must be precise (no approximations for critical details)
- Response should not contradict established Odido/telecom policies
- Should not provide information beyond what the context supports
- Must avoid speculation or assumptions about services not mentioned in context

Scoring guidelines:
- 1.0: All information is completely accurate and well-supported by context
- 0.8: Mostly accurate with only minor imprecisions that don't mislead customers  
- 0.6: Generally accurate but contains some questionable details that agents should verify
- 0.4: Partially accurate with clear errors that could mislead customers
- 0.2: Mostly inaccurate information that agents should not share
- 0.0: Completely inaccurate, harmful, or contradicts established policies

Additional rules:
- Be critical about factual claims - if context doesn't support a statement, the score cannot be above 0.5
- Consider impact on customer trust - inaccurate service details are more serious than minor formatting issues
- If the response correctly states limitations or directs to verify information, this supports accuracy

Please provide your evaluation in JSON format with a score between 0.0 and 1.0, and a brief comment explaining your reasoning.
"""

# 4. Helpfulness Evaluator - Is the response helpful to the customer?
helpfulness = """
You are an expert evaluator for a Dutch telecommunications customer service chatbot called Nova.

Your task is to evaluate whether the assistant's response is helpful to the customer.

Evaluation criteria:
- The response should provide actionable guidance or information
- The response should be practical and applicable to the customer's situation
- The response should guide the customer toward resolving their issue

Scoring guidelines:
- 1.0: Extremely helpful, provides clear actionable guidance
- 0.8: Very helpful, provides good guidance with minor gaps
- 0.6: Moderately helpful, provides some useful information
- 0.4: Somewhat helpful, limited practical value
- 0.2: Barely helpful, minimal practical guidance
- 0.0: Not helpful or potentially harmful

Please provide your evaluation in JSON format with a score between 0.0 and 1.0, and a brief comment explaining your reasoning.
"""

# 5. Language Quality Evaluator - Is the Dutch language usage appropriate?
language_quality = """
You are an expert evaluator for a Dutch telecommunications customer service agent chatbot called Nova.

Your task is to evaluate the quality of Dutch language usage in the response.

Evaluation criteria:
- The response should use proper Dutch grammar and syntax
- The response should use appropriate customer service tone and language
- The response should be clear and easy to understand for Dutch customers

Scoring guidelines:
- 1.0: Excellent Dutch language usage, professional and clear
- 0.8: Good Dutch usage with minor imperfections
- 0.6: Adequate Dutch usage, generally understandable
- 0.4: Poor Dutch usage with noticeable errors
- 0.2: Very poor Dutch usage, difficult to understand
- 0.0: Completely incorrect Dutch or incomprehensible

Please provide your evaluation in JSON format with a score between 0.0 and 1.0, and a brief comment explaining your reasoning.
"""

# 6. Intent Recognition Evaluator - Did the system correctly identify the customer's intent?
intent_recognition = """
You are an expert evaluator for a Dutch telecommunications customer service chatbot called Nova.

Your task is to evaluate whether the assistant correctly recognized the customer's intent (mobiel/thuis/onduidelijk).

Evaluation criteria:
- The response should align with the correct intent category (mobiel for mobile services, thuis for home services, onduidelijk for unclear)
- The response should address the appropriate service area
- The response should demonstrate understanding of the customer's domain of inquiry

Scoring guidelines:
- 1.0: Perfect intent recognition and response alignment
- 0.8: Good intent recognition with appropriate response
- 0.6: Adequate intent recognition, mostly appropriate response
- 0.4: Poor intent recognition, somewhat misaligned response
- 0.2: Very poor intent recognition, clearly wrong service area
- 0.0: Completely incorrect intent recognition

Please provide your evaluation in JSON format with a score between 0.0 and 1.0, and a brief comment explaining your reasoning.
"""
